trigger:
- master

variables:

  # Azure Resource Manager service connection 
  azureSubscription: 'vvp-pipeline-service-connection'

  # Agent VM image name
  # The depoly stage uses a Windows image which is required by AzureFileCopy@3 task
  vmImageName: 'ubuntu-latest'

  # DEBUG
  system.debug: true

  # Azure resources
  resourceGroup: 'vvp-pipeline-demo'
  servicePrincipal: 'http://vvp-pipeline-demo-service-principal'
  tenantId: '2925ee25-3bd0-402a-88f1-69307e6a39f3'
  keyVault: 'vvp-pipeline-keyvault'
  storageAccount: 'vvppipelinestorage'
  blobContainer: 'vvp-pipeline-artifacts'

  # Kubernetes
  kubernetesCluster: 'vvp-pipeline-cluster'
  kubernetesNamespace: 'vvp'

  # Ververica Platform
  vvpNamespace: 'default'
  vvpDeploymentTarget: '6ebbe4f9-0377-462a-9112-81a2ef4ea0b5'
  vvpJobJarPrefix: 'wiki-edits'

stages:

# Build stage
- stage: Build
  displayName: Build stage
  jobs:
  - job: PackageAndPublish
    displayName: Package and publish

    pool:
      vmImage: $(vmImageName)

    steps:

    - task: Maven@3
      displayName: Maven package
      inputs:
        mavenPomFile: 'pom.xml'

    - task: CopyFiles@2
      displayName: Stage artifacts
      inputs:
        SourceFolder: 'target'
        Contents: '$(vvpJobJarPrefix)-*.jar'
        TargetFolder: '$(build.artifactstagingdirectory)/artifacts'

    - task: PublishPipelineArtifact@1
      displayName: Publish artifacts
      inputs:
        targetPath: '$(build.artifactstagingdirectory)/artifacts'
        artifactName: JobJar

    # Passing variables cross stages is not supported in Azure Pipeline as of now
    # As a workaround: we publish it as an artifact then use it in another stage
    # This is based on Alessandro Segal's blog post:
    # https://medium.com/microsoftazure/how-to-pass-variables-in-azure-pipelines-yaml-tasks-5c81c5d31763
    - bash: |
        mkdir -p $(build.artifactstagingdirectory)/variables
        cd $(build.artifactstagingdirectory)/variables
        basename $(build.artifactstagingdirectory)/artifacts/$(vvpJobJarPrefix)-*.jar > artifactName
      displayName: Save variables

    - task: PublishPipelineArtifact@1
      displayName: Publish variables
      inputs:
        targetPath: '$(build.artifactstagingdirectory)/variables'
        artifactName: variables

# Deploy stage
- stage: Deploy
  displayName: Deploy stage
  dependsOn: Build
  condition: succeeded()

  jobs:
    - job: DownloadAndDeploy
      displayName: Download and deploy

      # We use a windows image here because AzureFileCopy@3 runs only on Windows
      pool:
        vmImage: 'windows-latest'

      steps:

      - task: DownloadPipelineArtifact@2
        displayName: Download artifacts
        inputs:
          artifact: 'JobJar'
          downloadPath: '$(build.artifactstagingdirectory)/artifacts' 

      - task: AzureFileCopy@3
        displayName: Deploy to blob storage
        inputs:
          sourcePath: '$(build.artifactstagingdirectory)/artifacts' 
          azureSubscription: '$(azureSubscription)'
          destination: azureBlob
          storage: $(storageAccount)
          containerName: $(blobContainer)
          BlobPrefix: 'artifacts/namespaces/$(vvpNamespace)'

# Submit stage
- stage: Submit
  displayName: Submit stage
  dependsOn: Deploy
  condition: succeeded()

  jobs:
    - job: SubmitFlinkJob
      displayName: Submit flink job

      pool:
        vmImage: $(vmImageName)

      steps:

        # extract commit hash
        # We use the commit hash in jar URI when POST/PATCH a deployment in VVP, e.g.,
        #     wasbs://...../job.jar?commit=e81c66d
        # This way VVP will suspend & start the flink job upon a PATCH action
        - bash: |
            commit=`echo $(Build.SourceVersion) | cut -c 1-7`
            echo "##vso[task.setvariable variable=commitHash]$commit"
          name: extractCommitHash

        - task: KubectlInstaller@0
          displayName: Install kubectl
          inputs: 
            kubectlVersion: 1.15.0

        - task: AzureKeyVault@1
          displayName: Get password
          inputs:
            azureSubscription: '$(azureSubscription)'
            KeyVaultName: '$(keyVault)'
            SecretsFilter: 'vvp-pipeline-demo-service-principal-password'

        # Here we download the artifact to get the artifactName
        - task: DownloadPipelineArtifact@2
          displayName: Download variables
          inputs:
            artifact: 'variables'
            downloadPath: '$(build.artifactstagingdirectory)/variables' 

        - bash: |
            name=`cat $(build.artifactstagingdirectory)/variables/artifactName`
            echo "##vso[task.setvariable variable=artifactName]$name"
          displayName: Set artifactName  
        
        - script: |
            az login --service-principal -u $(servicePrincipal) \
              -p $(vvp-pipeline-demo-service-principal-password) \
              --tenant $(tenantId)
          displayName: az login

        - script: |
            az aks get-credentials --resource-group $(resourceGroup) \
              --name $(kubernetesCluster)
          displayName: Get cluster credential

        - script: |
            kubectl port-forward service/vvp-ververica-platform 8080:80 \
              --namespace $(kubernetesNamespace) &
          displayName: Port forward

        - script: |
            findDeploymentId=`curl -X GET "http://localhost:8080/api/v1/namespaces/$(vvpNamespace)/deployments" \
            -H "accept: application/json" -s \
            | python -c '
            import sys, json
            j=json.loads(sys.stdin.read())
            for i in j["items"]:
              if i["metadata"]["name"] == "$(vvpJobJarPrefix)-deployment":
                print i["metadata"]["id"]
            '`
            echo "##vso[task.setvariable variable=deploymentId]$findDeploymentId"
          displayName: Check deployment

        - script: |
            echo "PATCH Deployment $(deploymentId)"
            curl -X PATCH "http://localhost:8080/api/v1/namespaces/$(vvpNamespace)/deployments/$(deploymentId)" \
            -H "accept: application/yaml" -H "Content-Type: application/yaml" -s -d '
            kind: Deployment
            apiVersion: v1
            spec:
              state: RUNNING
              template:
                spec:
                  artifact:
                    jarUri: >-
                      wasbs://$(blobContainer)@$(storageAccount).blob.core.windows.net/artifacts/namespaces/$(vvpNamespace)/$(artifactName)?commit=$(commitHash)
            '
          condition: ne(variables['deploymentId'], '')
          displayName: PATCH deployment

        - script: |
            curl -X POST "http://localhost:8080/api/v1/namespaces/$(vvpNamespace)/deployments" \
            -H "accept: application/yaml" -H "Content-Type: application/yaml" -s -d "
            kind: Deployment
            apiVersion: v1
            metadata:
              name: $(vvpJobJarPrefix)-deployment
              namespace: $(vvpNamespace)
            spec:
              state: RUNNING
              upgradeStrategy:
                kind: STATELESS
              restoreStrategy:
                kind: LATEST_SAVEPOINT
                allowNonRestoredState: false
              deploymentTargetId: $(vvpDeploymentTarget)
              template:
                metadata:
                  annotations: {}
                spec:
                  artifact:
                    kind: JAR
                    jarUri: >-
                      wasbs://$(blobContainer)@$(storageAccount).blob.core.windows.net/artifacts/namespaces/$(vvpNamespace)/$(artifactName)?commit=$(commitHash)
                    flinkVersion: 1.9
                    flinkImageRegistry: registry.platform.data-artisans.net/v2.0
                    flinkImageRepository: flink
                    flinkImageTag: 1.9.1-stream1-scala_2.12
                  parallelism: 1
                  resources:
                    jobmanager:
                      cpu: 1
                      memory: 1G
                    taskmanager:
                      cpu: 1
                      memory: 2G
                  flinkConfiguration: {}
                  logging:
                    log4jLoggers: {}
            status:
              state: CANCELLED
            "
          condition: eq(variables['deploymentId'], '')
          displayName: POST deployment

# Monitor stage
- stage: Monitor
  displayName: Monitor stage
  dependsOn: Submit
  condition: succeeded()

  jobs:
    # - job: Delay
    #   displayName: Delay a few minutes

    #   pool: server
 
    #   steps:
    #     - task: Delay@1
    #       inputs:
    #         delayForMinutes: '3'

    - job: MonitorFlinkJob
      dependsOn: Delay
      steps:

        - task: KubectlInstaller@0
          displayName: Install kubectl
          inputs: 
            kubectlVersion: 1.15.0

        - task: AzureKeyVault@1
          displayName: Get password
          inputs:
            azureSubscription: '$(azureSubscription)'
            KeyVaultName: '$(keyVault)'
            SecretsFilter: 'vvp-pipeline-demo-service-principal-password'
        
        - script: |
            az login --service-principal -u $(servicePrincipal) \
              -p $(vvp-pipeline-demo-service-principal-password) \
              --tenant $(tenantId)
          displayName: az login

        - script: |
            az aks get-credentials --resource-group $(resourceGroup) \
              --name $(kubernetesCluster)
          displayName: Get cluster credential

        - script: |
            kubectl port-forward service/vvp-ververica-platform 8080:80 \
              --namespace $(kubernetesNamespace) &
          displayName: Port forward

        - script: |
            state=`curl -X GET "http://localhost:8080/api/v1/namespaces/default/deployments" \
            -H "accept: application/json" -s \
            | python -c '
            import sys, json
            j=json.loads(sys.stdin.read())
            for i in j["items"]:
                  if i["metadata"]["name"] == "$(vvpJobJarPrefix)-deployment":
                          print i["status"]["state"]
            '`
            if [ "$state" != "RUNNING" ]; then
                exit 1
            fi
